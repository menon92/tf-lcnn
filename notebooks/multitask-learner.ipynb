{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "import sys\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "print(torch.__version__)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.4.1\n",
      "1.9.0+cpu\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "def cross_entropy_loss(logits, positive):\n",
    "    nlogp = -F.log_softmax(logits, dim=0)\n",
    "    return (positive * nlogp[1] + (1 - positive) * nlogp[0]).mean(2).mean(1)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "def sigmoid_l1_loss(logits, target, offset=0.0, mask=None):\n",
    "    logp = torch.sigmoid(logits) + offset\n",
    "    loss = torch.abs(logp - target)\n",
    "    if mask is not None:\n",
    "        w = mask.mean(2, True).mean(1, True)\n",
    "        w[w == 0] = 1\n",
    "        loss = loss * (mask / w)\n",
    "\n",
    "    loss = loss.mean(2).mean(1)\n",
    "    return loss"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "class MultitaskLearner(nn.Module):\n",
    "    def __init__(self, backbone):\n",
    "        super(MultitaskLearner, self).__init__()\n",
    "        self.backbone = backbone\n",
    "        # head_size = M.head_size\n",
    "        head_size = [[2], [1], [2]]\n",
    "        self.num_class = sum(sum(head_size, []))\n",
    "        self.head_off = np.cumsum([sum(h) for h in head_size])\n",
    "\n",
    "    def forward(self, input_dict, outputs, feature):\n",
    "        image = input_dict[\"image\"]\n",
    "        # outputs, feature = self.backbone(image)\n",
    "        result = {\"feature\": feature}\n",
    "        batch, channel, row, col = outputs[0].shape\n",
    "\n",
    "        T = input_dict[\"target\"].copy()\n",
    "        n_jtyp = T[\"jmap\"].shape[1]\n",
    "\n",
    "        # switch to CNHW\n",
    "        for task in [\"jmap\"]:\n",
    "            T[task] = T[task].permute(1, 0, 2, 3)\n",
    "        for task in [\"joff\"]:\n",
    "            T[task] = T[task].permute(1, 2, 0, 3, 4)\n",
    "            \n",
    "\n",
    "        offset = self.head_off # [2 3 5]\n",
    "        print(\"offset\", offset)\n",
    "        # loss_weight = M.loss_weight\n",
    "        loss_weight = {\n",
    "            'jmap': 8.0,\n",
    "            'lmap': 0.5,\n",
    "            'joff': 0.25,\n",
    "            'lpos': 1,\n",
    "            'lneg': 1,\n",
    "        }\n",
    "        losses = []\n",
    "        for stack, output in enumerate(outputs):\n",
    "            print(f'stack: {stack}')\n",
    "            print('output shape', output.shape)\n",
    "            # 5 x N x H X W\n",
    "            output = output.transpose(0, 1).reshape([-1, batch, row, col]).contiguous()\n",
    "            print('output shape after transpose + reshape', output.shape)\n",
    "            jmap = output[0 : offset[0]].reshape(n_jtyp, 2, batch, row, col)\n",
    "            lmap = output[offset[0] : offset[1]].squeeze(0)\n",
    "            print('joff shape', output[offset[1] : offset[2]].shape)\n",
    "            joff = output[offset[1] : offset[2]].reshape(n_jtyp, 2, batch, row, col)\n",
    "            \n",
    "            if stack == 0:\n",
    "                result[\"preds\"] = {\n",
    "                    \"jmap\": jmap.permute(2, 0, 1, 3, 4).softmax(2)[:, :, 1],\n",
    "                    \"lmap\": lmap.sigmoid(),\n",
    "                    \"joff\": joff.permute(2, 0, 1, 3, 4).sigmoid() - 0.5,\n",
    "                }\n",
    "                if input_dict[\"mode\"] == \"testing\":\n",
    "                    return result\n",
    "\n",
    "            L = OrderedDict()\n",
    "            L[\"jmap\"] = sum(\n",
    "                cross_entropy_loss(jmap[i], T[\"jmap\"][i]) for i in range(n_jtyp) # n_jtype {R, G, B} or gray\n",
    "            )\n",
    "            L[\"lmap\"] = (\n",
    "                F.binary_cross_entropy_with_logits(lmap, T[\"lmap\"], reduction=\"none\")\n",
    "                .mean(2)\n",
    "                .mean(1)\n",
    "            )\n",
    "            L[\"joff\"] = sum(\n",
    "                sigmoid_l1_loss(joff[i, j], T[\"joff\"][i, j], -0.5, T[\"jmap\"][i])\n",
    "                for i in range(n_jtyp)\n",
    "                for j in range(2)\n",
    "            )\n",
    "            for loss_name in L:\n",
    "                L[loss_name].mul_(loss_weight[loss_name])\n",
    "            losses.append(L)\n",
    "        result[\"losses\"] = losses\n",
    "        return result\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "outputs = [\n",
    "    # batch x channel x width x heigth\n",
    "    np.random.uniform(size=[2, 5, 128, 128]),\n",
    "    np.random.uniform(size=[2, 5, 128, 128])\n",
    "]\n",
    "outputs_torch = [torch.from_numpy(x) for x in outputs]\n",
    "\n",
    "feature = np.random.uniform(size=[2, 256, 128, 128])\n",
    "feature_torch = torch.from_numpy(feature)\n",
    "\n",
    "input_dict = {\n",
    "    'image': np.random.uniform(size=[2, 3, 512, 512]),\n",
    "    'target': {\n",
    "        'jmap': np.random.uniform(size=[2, 1, 128, 128]),\n",
    "        'joff': np.random.uniform(size=[2, 1, 2, 128, 128]),\n",
    "        'lmap': np.random.uniform(size=[2, 128, 128]),\n",
    "    }\n",
    "}\n",
    "\n",
    "input_dict_torch = {\n",
    "    'image': torch.from_numpy(input_dict['image']),\n",
    "    'target': {\n",
    "        'jmap': torch.from_numpy(input_dict['target']['jmap']),\n",
    "        'joff': torch.from_numpy(input_dict['target']['joff']),\n",
    "        'lmap': torch.from_numpy(input_dict['target']['lmap']),\n",
    "    },\n",
    "    'mode': 'training'\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "torch_model = MultitaskLearner(backbone=None)\n",
    "torch_model.train()\n",
    "losses = torch_model(input_dict_torch, outputs_torch, feature_torch)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "offset [2 3 5]\n",
      "stack: 0\n",
      "output shape torch.Size([2, 5, 128, 128])\n",
      "output shape after transpose + reshape torch.Size([5, 2, 128, 128])\n",
      "joff shape torch.Size([2, 2, 128, 128])\n",
      "stack: 1\n",
      "output shape torch.Size([2, 5, 128, 128])\n",
      "output shape after transpose + reshape torch.Size([5, 2, 128, 128])\n",
      "joff shape torch.Size([2, 2, 128, 128])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "for i, loss_stack in enumerate(losses['losses']):\n",
    "    print(f'loss stack {i}')\n",
    "    for name, loss in loss_stack.items():\n",
    "        print(f'{name}: {loss}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss stack 0\n",
      "jmap: tensor([5.7048, 5.7063], dtype=torch.float64)\n",
      "lmap: tensor([0.3667, 0.3664], dtype=torch.float64)\n",
      "joff: tensor([0.1984, 0.1989], dtype=torch.float64)\n",
      "loss stack 1\n",
      "jmap: tensor([5.7127, 5.7047], dtype=torch.float64)\n",
      "lmap: tensor([0.3669, 0.3674], dtype=torch.float64)\n",
      "joff: tensor([0.1984, 0.1982], dtype=torch.float64)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "3a4705feea52fcbee62e5c67e8ab7219e40d1a70e6db814be6b8c49c5caaa02a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}