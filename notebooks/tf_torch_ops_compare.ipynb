{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "print(torch.__version__)\n",
    "print(np.__version__)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.4.1\n",
      "1.9.0+cpu\n",
      "1.20.1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare `binary_cross_entropy_with_logits`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "y_true = np.random.uniform(size=[2, 128, 128])\n",
    "y_pred = np.random.uniform(size=[2, 128, 128])\n",
    "\n",
    "print(y_pred.shape)\n",
    "print(y_true.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2, 128, 128)\n",
      "(2, 128, 128)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "tf_loss = tf.keras.losses.binary_crossentropy(\n",
    "    y_true=y_true, y_pred=y_pred, from_logits=True,\n",
    ")\n",
    "\n",
    "print(tf_loss.shape)\n",
    "print(tf.reduce_mean(tf_loss, axis=1))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2, 128)\n",
      "tf.Tensor([0.73223665 0.73234737], shape=(2,), dtype=float64)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "torch_loss = F.binary_cross_entropy_with_logits(\n",
    "    torch.from_numpy(y_pred), torch.from_numpy(y_true), reduction=\"none\"\n",
    ")\n",
    "\n",
    "print(torch_loss.shape)\n",
    "print(torch_loss.mean(2).shape)\n",
    "print(torch_loss.mean(2).mean(1))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([2, 128, 128])\n",
      "torch.Size([2, 128])\n",
      "tensor([0.7322, 0.7323], dtype=torch.float64)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare `sigmoid_l1_loss`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "logits = np.random.uniform(size=[2, 128, 128])\n",
    "target = np.random.uniform(size=[2, 128, 128])\n",
    "offset = -0.5\n",
    "mask = np.random.uniform(size=[2, 128, 128])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "def sigmoid_l1_loss(logits, target, offset=0.0, mask=None):\n",
    "    logp = torch.sigmoid(logits) + offset\n",
    "    loss = torch.abs(logp - target)\n",
    "    if mask is not None:\n",
    "        w = mask.mean(2, True).mean(1, True)\n",
    "        w[w == 0] = 1\n",
    "        loss = loss * (mask / w)\n",
    "\n",
    "    loss = loss.mean(2).mean(1)\n",
    "    print(loss)\n",
    "    return loss\n",
    "\n",
    "sigmoid_l1_loss(\n",
    "    torch.from_numpy(logits),\n",
    "    torch.from_numpy(target), offset, torch.from_numpy(mask))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "logits: torch.Size([2, 128, 128])\n",
      "target: torch.Size([2, 128, 128])\n",
      "maks: torch.Size([2, 128, 128])\n",
      "tensor([0.3996, 0.3989], dtype=torch.float64)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0.3996, 0.3989], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "def sigmoid_l1_loss(logits, target, offset=0.0, mask=None):\n",
    "    logp = tf.math.sigmoid(logits) + offset\n",
    "    loss = tf.math.abs(logp - target)\n",
    "    if mask is not None:\n",
    "        w = tf.math.reduce_mean(mask, axis=2, keepdims=True)\n",
    "        condition = tf.equal(w, 0)\n",
    "        w = tf.where(condition, 1.0, w)\n",
    "        loss = loss * (mask / w)\n",
    "\n",
    "    loss = tf.math.reduce_mean(\n",
    "        tf.math.reduce_mean(loss, axis=2),\n",
    "        axis=1\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "tf_sig_l1_loss = sigmoid_l1_loss(logits, target, offset, mask)\n",
    "print(tf_sig_l1_loss)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor([0.39963411 0.39889329], shape=(2,), dtype=float64)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "3a4705feea52fcbee62e5c67e8ab7219e40d1a70e6db814be6b8c49c5caaa02a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}